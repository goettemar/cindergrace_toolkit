{
  "version": "1.1.0",
  "updated": "2025-01-01",
  "target_folders": [
    "checkpoints",
    "clip_vision",
    "controlnet",
    "diffusion_models",
    "diffusion_models/wan",
    "loras",
    "loras/wan",
    "text_encoders",
    "upscale_models",
    "vae",
    "LLM"
  ],
  "workflows": {
    "gcv_wan_2.2_14b_i2v": {
      "name": "WAN 2.2 14B I2V",
      "description": "Image to Video mit WAN 2.2 14B",
      "category": "video",
      "model_sets": {
        "bf16": {
          "name": "BF16 Full (24GB+ VRAM)",
          "description": "Volle Qualität, benötigt 24GB+ VRAM",
          "vram_gb": 24,
          "recommended_platform": "runpod",
          "models": ["wan22_14b_bf16", "wan22_vae", "wan22_clip", "wan22_clip_vision"]
        },
        "fp8": {
          "name": "FP8 (16GB VRAM)",
          "description": "Quantisiert, läuft auf 16GB",
          "vram_gb": 16,
          "models": ["wan22_14b_fp8", "wan22_vae", "wan22_clip", "wan22_clip_vision"]
        }
      }
    },
    "gcv_wan_2.2_5b_i2v": {
      "name": "WAN 2.2 5B I2V",
      "description": "Image to Video mit WAN 2.2 5B (kleiner, schneller)",
      "category": "video",
      "model_sets": {
        "bf16": {
          "name": "BF16 (12GB VRAM)",
          "vram_gb": 12,
          "models": ["wan22_5b_bf16", "wan22_vae", "wan22_clip", "wan22_clip_vision"]
        }
      }
    },
    "gcv_wan_2.2_14B_i2v_gguf": {
      "name": "WAN 2.2 14B I2V GGUF",
      "description": "GGUF quantisierte Version - KEIN LoRA Support!",
      "category": "video",
      "model_sets": {
        "q8": {
          "name": "GGUF Q8 (14GB VRAM)",
          "description": "Quantisiert, kein LoRA Support",
          "vram_gb": 14,
          "models": ["wan22_14b_gguf_q8", "wan22_vae", "wan22_clip", "wan22_clip_vision"]
        }
      }
    },
    "gcl_wan2.2_14B_s2v": {
      "name": "WAN 2.2 14B SVI (Long Video)",
      "description": "Smooth Video Interpolation für lange Videos",
      "category": "video",
      "model_sets": {
        "bf16": {
          "name": "BF16 Full (24GB+ VRAM)",
          "description": "HIGH + LOW Noise Models + SVI LoRA",
          "vram_gb": 24,
          "recommended_platform": "runpod",
          "models": [
            "wan22_14b_high_bf16",
            "wan22_14b_low_bf16",
            "wan22_vae",
            "wan22_clip",
            "wan22_clip_vision",
            "svi_lora",
            "lightning_lora"
          ]
        }
      }
    },
    "gcp_flux1_krea_dev_xxx": {
      "name": "FLUX Krea Dev",
      "description": "FLUX.1 Dev mit Krea Workflow",
      "category": "image",
      "model_sets": {
        "full": {
          "name": "Full (24GB+ VRAM)",
          "description": "Volle bf16 Modelle",
          "vram_gb": 24,
          "models": ["flux_dev", "flux_vae", "t5xxl", "clip_l"]
        },
        "fp8": {
          "name": "FP8 (16GB VRAM)",
          "description": "Quantisierte Version",
          "vram_gb": 16,
          "models": ["flux_dev_fp8", "flux_vae", "t5xxl_fp8", "clip_l"]
        }
      }
    },
    "gcp_sdxl_lora": {
      "name": "SDXL + LoRA",
      "description": "Stable Diffusion XL mit LoRA Support",
      "category": "image",
      "model_sets": {
        "default": {
          "name": "Standard (8GB VRAM)",
          "vram_gb": 8,
          "models": ["sdxl_base", "sdxl_vae"]
        }
      }
    },
    "gca_florence2_caption": {
      "name": "Florence2 Caption",
      "description": "Automatische Bildbeschreibung mit Florence2",
      "category": "analysis",
      "model_sets": {
        "default": {
          "name": "Standard",
          "vram_gb": 8,
          "models": ["florence2_large"]
        }
      }
    },
    "gcv_ltvx_i2v": {
      "name": "LTVX I2V",
      "description": "LTX Video Image to Video",
      "category": "video",
      "model_sets": {
        "default": {
          "name": "Standard (12GB VRAM)",
          "vram_gb": 12,
          "models": ["ltvx_video", "ltvx_vae"]
        }
      }
    }
  },
  "models": {
    "wan22_14b_bf16": {
      "name": "WAN 2.2 14B (bf16)",
      "filename": "wan2.2_i2v_720p_14B_bf16.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_720p_14B_bf16.safetensors",
      "size_mb": 28000,
      "target_path": "diffusion_models/wan"
    },
    "wan22_14b_fp8": {
      "name": "WAN 2.2 14B (fp8)",
      "filename": "wan2.2_i2v_720p_14B_fp8_e4m3fn.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_720p_14B_fp8_e4m3fn.safetensors",
      "size_mb": 14000,
      "target_path": "diffusion_models/wan"
    },
    "wan22_14b_high_bf16": {
      "name": "WAN 2.2 14B HIGH Noise (bf16)",
      "filename": "wan2.2_i2v_720p_14B_bf16_HIGH.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_720p_14B_bf16_HIGH.safetensors",
      "size_mb": 25000,
      "target_path": "diffusion_models/wan"
    },
    "wan22_14b_low_bf16": {
      "name": "WAN 2.2 14B LOW Noise (bf16)",
      "filename": "wan2.2_i2v_720p_14B_bf16_LOW.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_720p_14B_bf16_LOW.safetensors",
      "size_mb": 25000,
      "target_path": "diffusion_models/wan"
    },
    "wan22_14b_gguf_q8": {
      "name": "WAN 2.2 14B GGUF Q8",
      "filename": "wan2.2_i2v_720p_14B_Q8_0.gguf",
      "url": "https://huggingface.co/city96/Wan2.2-I2V-14B-gguf/resolve/main/wan2.2_i2v_720p_14B_Q8_0.gguf",
      "size_mb": 15000,
      "target_path": "diffusion_models/wan"
    },
    "wan22_5b_bf16": {
      "name": "WAN 2.2 5B (bf16)",
      "filename": "wan2.2_i2v_480p_5B_bf16.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_480p_5B_bf16.safetensors",
      "size_mb": 10000,
      "target_path": "diffusion_models/wan"
    },
    "wan22_vae": {
      "name": "WAN 2.2 VAE",
      "filename": "wan_2.2_vae.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.2_vae.safetensors",
      "size_mb": 250,
      "target_path": "vae"
    },
    "wan22_clip": {
      "name": "WAN 2.2 CLIP (UMT5-XXL)",
      "filename": "umt5_xxl_encoder_q4_k_m.gguf",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_encoder_q4_k_m.gguf",
      "size_mb": 5000,
      "target_path": "text_encoders"
    },
    "wan22_clip_vision": {
      "name": "WAN 2.2 CLIP Vision",
      "filename": "clip_vision_h.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors",
      "size_mb": 3500,
      "target_path": "clip_vision"
    },
    "svi_lora": {
      "name": "SVI LoRA",
      "filename": "svi.safetensors",
      "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/svi.safetensors",
      "size_mb": 800,
      "target_path": "loras/wan"
    },
    "lightning_lora": {
      "name": "Lightning LoRA",
      "filename": "wan_lighting_lora.safetensors",
      "url": "https://huggingface.co/Kijai/WanVideo_comfy/resolve/main/wan_lighting_lora.safetensors",
      "size_mb": 400,
      "target_path": "loras/wan"
    },
    "flux_dev": {
      "name": "FLUX.1 Dev",
      "filename": "flux1-dev.safetensors",
      "url": "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/flux1-dev.safetensors",
      "size_mb": 24000,
      "target_path": "diffusion_models",
      "note": "Requires HF token"
    },
    "flux_dev_fp8": {
      "name": "FLUX.1 Dev (fp8)",
      "filename": "flux1-dev-fp8.safetensors",
      "url": "https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev-fp8.safetensors",
      "size_mb": 12000,
      "target_path": "diffusion_models"
    },
    "flux_vae": {
      "name": "FLUX VAE",
      "filename": "ae.safetensors",
      "url": "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/ae.safetensors",
      "size_mb": 300,
      "target_path": "vae"
    },
    "t5xxl": {
      "name": "T5-XXL",
      "filename": "t5xxl_fp16.safetensors",
      "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors",
      "size_mb": 9500,
      "target_path": "text_encoders"
    },
    "t5xxl_fp8": {
      "name": "T5-XXL (fp8)",
      "filename": "t5xxl_fp8_e4m3fn.safetensors",
      "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors",
      "size_mb": 4700,
      "target_path": "text_encoders"
    },
    "clip_l": {
      "name": "CLIP-L",
      "filename": "clip_l.safetensors",
      "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
      "size_mb": 250,
      "target_path": "text_encoders"
    },
    "sdxl_base": {
      "name": "SDXL Base",
      "filename": "sd_xl_base_1.0.safetensors",
      "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors",
      "size_mb": 6900,
      "target_path": "checkpoints"
    },
    "sdxl_vae": {
      "name": "SDXL VAE",
      "filename": "sdxl_vae.safetensors",
      "url": "https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors",
      "size_mb": 350,
      "target_path": "vae"
    },
    "florence2_large": {
      "name": "Florence2 Large",
      "filename": "florence2-large",
      "url": "https://huggingface.co/microsoft/Florence-2-large",
      "size_mb": 1500,
      "target_path": "LLM",
      "note": "HuggingFace model, needs special handling"
    },
    "ltvx_video": {
      "name": "LTX Video",
      "filename": "ltx-video-2b-v0.9.safetensors",
      "url": "https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltx-video-2b-v0.9.safetensors",
      "size_mb": 9000,
      "target_path": "checkpoints"
    },
    "ltvx_vae": {
      "name": "LTX VAE",
      "filename": "ltx_video_vae.safetensors",
      "url": "https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltx_video_vae.safetensors",
      "size_mb": 200,
      "target_path": "vae"
    }
  }
}
